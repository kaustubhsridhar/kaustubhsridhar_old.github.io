---
layout: default
title: Welcome To My Homepage
---
<!--- Comment out below: it is to remove website cache for development -->
<!-- <meta http-equiv='cache-control' content='no-cache'> 
<meta http-equiv='expires' content='0'> 
<meta http-equiv='pragma' content='no-cache'> -->

<div class="blurb">
	<font size="-1"><h1>Hi there, I'm Kaustubh Sridhar!</h1>
	<img src="/dp.png" alt="Kaustubh Sridhar" align="right" style="width:30%; padding: 10px;" class="img_dp">
	<p>I'm a PhD candidate in <a href="https://www.ese.upenn.edu/">Electrical and Systems Enginnering</a> at the University of Pennsylvania, where I'm advised by <a href="https://www.cis.upenn.edu/~lee/home/index.shtml">Insup Lee</a>, <a href="https://www.seas.upenn.edu/~weimerj/research.html">James Weimer</a> and <a href="https://www.seas.upenn.edu/directory/profile.php?ID=91">Oleg Sokolsky</a>. 
	My CV can be found <a href="https://kaustubhsridhar.github.io/cv.pdf">here</a>.</p>
	
	<p>I will be working in the space of RL for anomaly detection at <a href="https://aws.amazon.com/machine-learning/ai-services/">Amazon Web Services (AWS) AI Lab</a> in the upcoming summer. Previously, I did a summer internship at <a href="https://www.argo.ai/">Argo AI</a>'s autonomous vehicle security and functional safety (FuSa) team in the summer of 2021. Before that, I graduated with honors from the <a href="https://www.iitb.ac.in/">Indian Institute of Technology Bombay</a> and spent a summer as an intern at <a href="https://ece.duke.edu/">Duke University</a>.</p>
	
	<h3>Research</h3>
	<p>My research aims to build systems that can learn quickly and are robust to long tail scenarios. Towards that goal, I'm working on, </p>

	<h5><ul>
		<li><a id="RL">Efficient Deep Reinforcement Learning</a></li>
	</ul></h5>

	<img src="/images/fetch_4blocks.gif" alt="craft_fetch" align="left" style="width:300px; height:150px; padding: 10px;" class="img_rect">
	<p><a id="OptionTemplates"><a href="https://arxiv.org/abs/2202.12967">Exploring with Sticky Mittens: Reinforcement Learning with Expert Interventions via Option Templates</a></a></p>
	<p><a href="https://sites.google.com/site/duttasouradeep39/">Souradeep Dutta</a>, <b>Kaustubh Sridhar</b>, <a href="https://obastani.github.io/">Osbert Bastani</a>, <a href="https://statistics.wharton.upenn.edu/profile/dobriban/">Edgar Dobriban</a>, James Weimer, Insup Lee, Julia Parish-Morris</p>
	<!--<p>Submitted to <a href="https://icml.cc/">ICML</a> 2022</p>-->
	<p><a href="https://arxiv.org/abs/2202.12967">arXiv</a> / <a href="https://sites.google.com/view/stickymittens">website</a> / code (TBA) </p>
	<p><small>Environments with sparse rewards and long horizons pose a significant challenge for current reinforcement learning algorithms. A key feature enabling humans to learn challenging control tasks is that they often receive expert intervention that enables them to understand the high-level structure of the task before mastering low-level control actions. We propose a framework for leveraging expert intervention to solve long-horizon reinforcement learning tasks. We consider option templates, which are specifications encoding a potential option that can be trained using reinforcement learning. We formulate expert intervention as allowing the agent to execute option templates before learning an implementation. This enables them to use an option, before committing costly resources to learning it. We evaluate our approach on three challenging reinforcement learning problems, showing that it out performs state-of-the-art approaches by an order of magnitude.
		</small></p>
		
	<h5><ul>
		<li><a id="RobustDL">Robust Deep Learning</a></li>
	</ul></h5>
		
	<img src="/images/trajectories.gif" alt="PoE" align="left" style="width:230px; height:150px; padding: 45px;" class="img_rect">
	<p><a id="PoE"><a href="https://arxiv.org/abs/2106.02078">Improving Neural Network Robustness via Persistency of Excitation</a></a></p>
	<p><b>Kaustubh Sridhar</b>, Oleg Sokolsky, Insup Lee, James Weimer</p>
	<p><a href="https://acc2022.a2c2.org/">ACC</a> 2022</p>
	<p><a href="https://arxiv.org/abs/2106.02078">arXiv</a> / <a href="https://github.com/kaustubhsridhar/PoE-robustness">code</a> / <a href="https://docs.google.com/presentation/d/e/2PACX-1vTNJ5e35OwacfBx19V0FjeEaBRj8cGTaFngpP1KdrWxnDFShwFR9zAZyfLWghlDlQ/pub?start=true&loop=true&delayms=3000">poster</a> / <a href="https://youtu.be/LtFMKZq8PuA">video</a> / <a href="https://robustbench.github.io/">leaderboard</a></p>
	<p><small>Improving adversarial robustness of neural networks remains a major challenge. Fundamentally, training a neural network via gradient descent is a parameter estimation problem. In adaptive control, maintaining persistency of excitation (PoE) is integral to ensuring convergence of parameter estimates in dynamical systems to their true values. We show that parameter estimation with gradient descent can be modeled as a sampling of an adaptive linear time-varying continuous system. Leveraging this model, and with inspiration from Model-Reference Adaptive Control, we prove a sufficient condition to constrain gradient descent updates to reference persistently excited trajectories converging to the true parameters. The sufficient condition is achieved when the learning rate is less than the inverse of the Lipschitz constant of the gradient of loss function. Our experimental results in both standard and adversarial training illustrate that networks trained with the PoE-motivated learning rate schedule have similar clean accuracy but are significantly more robust to adversarial attacks than state-of-the-art models.
		</small></p>
	
	<br>
	<img src="/images/visionguard.png" alt="visionguard" align="left" style="width:250px; height:100px; padding: 35px;" class="img_rect">
	<p><a id="VisionGuard"><a href="https://arxiv.org/abs/2002.09792">Real-Time detectors for Digital and Physical Adversarial Inputs to Perception Systems</a></a></p>
	<p><a href="https://sites.google.com/view/kantaros/">Yiannis Kantaros</a>, Taylor Carpenter, <b>Kaustubh Sridhar</b>, Yahan Yang, Insup Lee, James Weimer</p>
	<p><a href="http://iccps.acm.org/2021/">ICCPS</a> 2021</p>
	<p><a href="https://arxiv.org/abs/2002.09792">arXiv</a> / <a href="https://dl.acm.org/doi/abs/10.1145/3450267.3450535">proceedings</a> / <a href="https://advnet.seas.upenn.edu/#">dataset webpage</a></p>
	<p><small>We propose a novel attack- and dataset-agnostic and real-time detector for digital / physical adversarial inputs to DNN-based perception systems. We demonstrate the efficiency of the proposed detector on ImageNet, a task that is computationally challenging for the majority of relevant defenses, and on physically attacked traffic signs that may be encountered in real-time autonomy applications.</small></p>

	<br>
	<img src="/images/codit.png" alt="codit" align="left" style="width:260px; height:135px; padding: 30px;" class="img_rect">
	<p><a id="CODiT"><a href="">CODiT: Conformal Out-of-distribution Detection in Time-series Data</a></a></p>
	<p><a href="https://scholar.google.com/citations?user=tMfMh_wAAAAJ&hl=en">Ramneet Kaur</a>, <b>Kaustubh Sridhar</b>, <a href="https://sangdon.github.io/">Sangdon Park</a>, <a href="https://susmitjha.github.io/">Susmit Jha</a>, <a href="https://scholar.google.com/citations?user=N9eSuR4AAAAJ&hl=en">Anirban Roy</a>, Oleg Sokolsky, Insup Lee</p>
	<!--<p>Submitted to <a href="https://www.ijcai.org/">IJCAI</a> 2022</p>-->
	<p><a href="https://openreview.net/pdf?id=9j0wD5iV5f">paper</a> / code (TBA)</p>
	<p><small>Machine learning models are prone to making incorrect predictions on inputs that are far from the training distribution. This hinders their deployment in safety-critical applications such as autonomous vehicles and healthcare. The detection of a shift from the training distribution of individual samples has gained attention. A number of techniques have been proposed for such out-of-distribution (OOD) detection. But in many applications, the inputs to a machine learning model form a temporal sequence and existing techniques do not exploit these temporal relationships or provide any guarantees on detection. We develop a self-supervised learning approach, CODiT for OOD detection of time-series data with guarantees on detection by using the deviation in the in-distribution (iD) temporal equivariance learned by a model as the non-conformity measure in the conformal anomaly detection framework. We illustrate the efficacy of CODiT by achieving state-of-the-art results on computer vision datasets in autonomous driving, and the GAIT sensory dataset.
		</small></p>

	<h5><ul>
		<li><a id="CPS">Safety and Security of Autonomous Vehicles and other Cyber-Physical Systems.</a></li>
	</ul></h5>

	<!--<img src="/images/mpc.png" alt="mpc" align="left" style="width:300px; height:150px; padding: 10px;" class="img_rect">
	<p><a id="MPCRecovery"><a href="">Real-Time Model-Predictive Attack-Recovery for Complex Cyber-Physical Systems</a></a></p>
	<p>Lin Zhang, Pengyuan Lu, Mengyu Liu, <b>Kaustubh Sridhar</b>, <a href="https://sites.google.com/site/fanxink/">Fanxin Kong</a>, Oleg Sokolsky, Insup Lee</p>
	<p>preprint (TBA) / code (TBA)</p>
	<p><small>We propose a real-time model-predictive recovery method against sensor attacks that can safely and smoothly recover a CPS before its recovery deadline and maintain it in a target state set once driven into it. A time oracle computes the recovery deadline dynamically at run time by leveraging reachability-based techniques. The recovery control operates in real-time on non-linear systems with Taylor model flowpipe approximations and utilizes uncompromised sensors to eliminate uncertainties. Our approach produces the most-accurate recovery with minimal computational overhead in a variety of compromised non-linear systems.
		</small></p>-->

	<!--<br>-->
	<img src="/images/framework_wide.png" alt="framework" align="left" style="width:300px; height:150px; padding: 10px;" class="img_rect">
	<p><a id="Checkpointing"><a href="https://arxiv.org/abs/2205.08650">A Framework for Checkpointing and Recovery of Hierarchical Cyber-Physical Systems</a></a></p>
	<p><b>Kaustubh Sridhar</b>, <a href="http://cs.rpi.edu/~ivanor/">Radoslav Ivanov</a>, Marcio Juliato*, Manoj Sastry*, Vuk Lesi*, Lily Yang*, James Weimer, Oleg Sokolsky, Insup Lee</p>
	<p>Collaboration with Intel Labs(*).</p>
	<p><a href="https://arxiv.org/abs/2205.08650">arXiv</a> / <a href="https://github.com/kaustubhsridhar/checkpointing_and_recovery">code</a></a></p>
	<p><small>We tackle the problem of making complex resource-constrained cyber-physical systems (CPS) resilient to sensor anomalies. We present a framework for checkpointing and roll-forward recovery of state-estimates in nonlinear, hierarchical CPS with anomalous sensor data. A simulated ground robot case-study demonstrates its scalability and improved performance over an Extended Kalman Filter.</small></p>

	<h4>Undergraduate Research</h4>
	<p>Information about my research at Duke University, IIT Bombay and the Indian Institute of Science (IISc) Banglore on ground and aerial robotics can be found <a href="https://kaustubhsridhar.github.io/undergrad.html">here</a>.</p>

	<h4>Miscellaneous</h4>
	<p>I enjoy a game of tennis and squash and avidly read science-fiction.</p>
	
	<p>Some other links: </p>
	<ul class="contacts">
		<li><a href="https://linkedin.com/in/kaustubh-sridhar-8636797a/">LinkedIn</a></li>
		<li><a href="https://twitter.com/_k_sridhar">Twitter</a></li>
		<li><a href="https://www.semanticscholar.org/author/Kaustubh-Sridhar/2065757795">Semantic Scholar (shows latest citations)</a></li>
		<li><a href="https://scholar.google.com/citations?hl=en&tzom=240&user=V-HiOnUAAAAJ">Google Scholar</a></li>
	</ul></font>
</div> 

